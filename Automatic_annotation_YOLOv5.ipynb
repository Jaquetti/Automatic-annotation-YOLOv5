{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaquetti/Automatic-annotation-YOLOv5/blob/main/Automatic_annotation_YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnsVmtRJbavn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Este notebook utiliza a yolov5s treinada para auto-anotar imagens, sejam elas provenientes de conjunto de imagens em pastas ou diretamente de vídeos. Ao final as imagens são salvas em uma nova pasta junta ao seus txts correpondentes formatados padrão yolo.**"
      ],
      "metadata": {
        "id": "D6BvCB14KBHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lendo o modelo já treinado com uma confiança de 70%"
      ],
      "metadata": {
        "id": "FDMzgqskLH2b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q6XJ6lER16V"
      },
      "outputs": [],
      "source": [
        "#Lendo modelo\n",
        "model = torch.hub.load('/content/drive/MyDrive/yolov5_LIV/yolov5', 'custom', path='/content/drive/MyDrive/yolov5_LIV/yolov5/runs/train/exp148/weights/best.pt', source='local') \n",
        "\n",
        "#Modelo irá mostrar apenas predições com 70% de certeza\n",
        "model.conf = 0.7"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auto-anotação de imagens provenientes de pastas"
      ],
      "metadata": {
        "id": "XKI_t3HkLPy0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKmw5uNpbWpM"
      },
      "outputs": [],
      "source": [
        "#Setando o caminho onde a imagem está localizado\n",
        "path_img = '/content/drive/MyDrive/d1/'\n",
        "\n",
        "#Caminho onde os arquivos serão salvos\n",
        "save_path ='/content/drive/MyDrive/d1_anno/'\n",
        "\n",
        "try:\n",
        "  os.mkdir(save_path)\n",
        "  print('Criando o diretório')\n",
        "except:\n",
        "  print('Diretório encontrado')\n",
        "\n",
        "#Carregando a imagem\n",
        "#Variáveis para se utilizar no salvamento dos frames e anotações\n",
        "\n",
        "#Flag que vai controlar a taxa de frames que serão processados \n",
        "frame_count = 0\n",
        "\n",
        "#Rodando o loop equanto o vídeo não estiver finalizado \n",
        "for i in range(len(os.listdir(path_img))):\n",
        "  #Lendo cada Frame\n",
        "  frame = cv2.imread(path_img+os.listdir(path_img)[i])\n",
        " \n",
        "  #Converten do tipo numpy array para PIL.image (aumenta a precisão por algum motivo)\n",
        "  frame_pil = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "  frame_pil = Image.fromarray(frame_pil)\n",
        "\n",
        "  #Enviando a imagem para a rede\n",
        "  results = model(frame_pil,  size=1280)\n",
        "        \n",
        "  #Transformando as predições do modelo em formato pandas DataFrame \n",
        "  dados = results.pandas().xyxy[0]\n",
        "  \n",
        "  #Realizando o préprocessamento necessário para transformar as predições no \n",
        "  #formato padrão das anotações do modelo YOLO \n",
        "  im_w, im_h = frame_pil.size\n",
        "  dados = dados[['class','xmin', 'ymin', 'xmax', 'ymax']]\n",
        "  dados['W'] = dados['xmax']-dados['xmin']\n",
        "  dados['H'] = dados['ymax']-dados['ymin']\n",
        "  dados['Norm(xMin)'] = (dados['xmin']+(dados['W']/2))/im_w\n",
        "  dados['Norm(yMin)'] = (dados['ymin']+(dados['H']/2))/im_h\n",
        "  dados['Norm(W)'] = (dados['W'])/im_w\n",
        "  dados['Norm(H)'] = (dados['H'])/im_h\n",
        "  dados = dados.drop(['xmin',\t'ymin',\t'xmax',\t'ymax', 'H','W'], axis = 1)\n",
        "\n",
        " \n",
        "  textfile = open(save_path+(os.listdir(path_img)[i])[:-4]+\".txt\", \"w\")\n",
        "  for j in range(len(dados)):\n",
        "      lista = dados.iloc[j].to_list()\n",
        "      lista[0] = int(lista[0])\n",
        "      listToStr = ' '.join(map(str, lista))\n",
        "      textfile.write(listToStr + \"\\n\")\n",
        "\n",
        "  textfile.close()\n",
        "  cv2.imwrite(save_path+os.listdir(path_img)[i], frame)\n",
        "\n",
        "print(len(os.listdir(save_path)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auto anotação de frames provenientes de vídeos"
      ],
      "metadata": {
        "id": "q2SAKSDsLYfj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JzXN_Ut0SYR"
      },
      "outputs": [],
      "source": [
        "#Setando o caminho onde o vídeo está localizado\n",
        "path_video = '/content/drive/MyDrive/video/v2.mp4'\n",
        "\n",
        "#Caminho onde os arquivos serão salvos\n",
        "save_path = '/content/drive/MyDrive/imagens_auto_anotadas/'\n",
        "\n",
        "try:\n",
        "  os.mkdir( '/content/drive/MyDrive/imagens_auto_anotadas/')\n",
        "  print('Criando o diretório')\n",
        "except:\n",
        "  print('Diretório encontrado')\n",
        "\n",
        "#Carregando o vídeo \n",
        "cap = cv2.VideoCapture(path_video)\n",
        "\n",
        "#Variáveis para se utilizar no salvamento dos frames e anotações\n",
        "num_frame = 0\n",
        "name_frame = path_vid.rsplit('/',1)[1].rsplit('.',1)[0]+'_frame_'\n",
        "\n",
        "#Flag que vai controlar a taxa de frames que serão processados \n",
        "frame_count = 0\n",
        "\n",
        "ret = True\n",
        "\n",
        "#Rodando o loop equanto o vídeo não estiver finalizado \n",
        "while ret==True:\n",
        "\n",
        "  #Lendo cada Frame\n",
        "  ret, frame = cap.read()\n",
        "  \n",
        "  #Para quando o vídeo acabar\n",
        "\n",
        "\n",
        "  #Vai pegar um vídeo a cada 10 frames\n",
        "  frame_count+=1\n",
        "  if frame_count ==3:\n",
        "    #Variáveis para salvamento\n",
        "    num_frame +=1 \n",
        "    save_name = name_frame+str(num_frame)\n",
        "\n",
        "    frame_count = 0\n",
        "\n",
        "    if ret == True:\n",
        "        #Converten do tipo numpy array para PIL.image (aumenta a precisão por algum motivo)\n",
        "        frame_pil = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame_pil = Image.fromarray(frame_pil)\n",
        "\n",
        "        #Enviando a imagem para a rede\n",
        "        results = model(frame_pil,  size=1280)\n",
        "        \n",
        "        #Transformando as predições do modelo em formato pandas DataFrame \n",
        "        dados = results.pandas().xyxy[0]\n",
        "        \n",
        "        #Realizando o préprocessamento necessário para transformar as predições no \n",
        "        #formato padrão das anotações do modelo YOLO \n",
        "        im_w, im_h = im.size\n",
        "        dados = dados[['class','xmin', 'ymin', 'xmax', 'ymax']]\n",
        "        dados['W'] = dados['xmax']-dados['xmin']\n",
        "        dados['H'] = dados['ymax']-dados['ymin']\n",
        "        dados['Norm(xMin)'] = (dados['xmin']+(dados['W']/2))/im_w\n",
        "        dados['Norm(yMin)'] = (dados['ymin']+(dados['H']/2))/im_h\n",
        "        dados['Norm(W)'] = (dados['W'])/im_w\n",
        "        dados['Norm(H)'] = (dados['H'])/im_h\n",
        "        dados = dados.drop(['xmin',\t'ymin',\t'xmax',\t'ymax', 'H','W'], axis = 1)\n",
        "\n",
        "        #Transformando o Dataframe em txt\n",
        "        textfile = open(save_path+save_name+\".txt\", \"w\")\n",
        "        for i in range(len(dados)):\n",
        "            lista = dados.iloc[i].to_list()\n",
        "            lista[0] = int(lista[0])\n",
        "            listToStr = ' '.join(map(str, lista))\n",
        "            textfile.write(listToStr + \"\\n\")\n",
        "\n",
        "        textfile.close()\n",
        "        #Salvando a imagem\n",
        "        cv2.imwrite(save_path+save_name+\".jpg\", frame)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Automatic annotation YOLOv5.ipynb",
      "provenance": [],
      "mount_file_id": "1h2lyp3JCc-TeGJP_NCO7qT4-vxMPXc6A",
      "authorship_tag": "ABX9TyN4JTgkXtEM/Elfb3TAnIFz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}